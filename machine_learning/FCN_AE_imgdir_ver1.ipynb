{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NgEyX5YHbQN"
      },
      "outputs": [],
      "source": [
        "# global variables\n",
        "pix_per_side = 64 # image size\n",
        "\n",
        "# Define the transformation\n",
        "transform = transforms.Compose([\n",
        "  transforms.Resize((pix_per_side, pix_per_side)),\n",
        "  transforms.Grayscale(),  # Convert to grayscale\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize grayscale image\n",
        "])\n",
        "\n",
        "# Load the images from a directory\n",
        "dataset = ImageFolder('C:/MyPythonCoding/MyDeepLearningCoding/images_512x512', transform=transform)\n",
        "\n",
        "# Create a DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, drop_last=True)\n",
        "\n",
        "print('dataloader created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zwbFr2UIKOj"
      },
      "outputs": [],
      "source": [
        "# create a class for the model\n",
        "def createTheMNISTAE():\n",
        "\n",
        "  class aenet(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "\n",
        "      self.input = nn.Linear(pix_per_side*pix_per_side,600)\n",
        "\n",
        "      self.enc = nn.Linear(600,16)\n",
        "\n",
        "      self.lat = nn.Linear(16,600)\n",
        "\n",
        "      self.dec = nn.Linear(600,pix_per_side*pix_per_side)\n",
        "\n",
        "    # forward pass\n",
        "    def forward(self,x):\n",
        "      x = F.relu( self.input(x) )\n",
        "      x = F.relu( self.enc(x) )\n",
        "      x = F.relu( self.lat(x) )\n",
        "      y = torch.sigmoid( self.dec(x) )\n",
        "      return y\n",
        "\n",
        "  # create the model instance\n",
        "  net = aenet()\n",
        "\n",
        "  lossfun = nn.MSELoss()\n",
        "  optimizer = torch.optim.Adam(net.parameters(),lr=.001)\n",
        "\n",
        "  return net,lossfun,optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOZXNRLqIEeM"
      },
      "outputs": [],
      "source": [
        "def function2trainTheModel():\n",
        "  numepochs = 250\n",
        "\n",
        "  net,lossfun,optimizer = createTheMNISTAE()       # create a new model\n",
        "\n",
        "  losses = []     # initialize losses\n",
        "  for epochi in range(numepochs):\n",
        "    if epochi == 0: print('training has started')\n",
        "    for images, _ in dataloader:\n",
        "      images = images.view(images.size(0), -1)  # Flatten the images\n",
        "      yHat = net(images)              # forward pass\n",
        "      loss = lossfun(yHat,images)     # loss\n",
        "\n",
        "      optimizer.zero_grad()           # backprop\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # losses in this epoch\n",
        "      losses.append( loss.item() )\n",
        "    print (epochi,' of ',numepochs,'loss: ',loss.item())\n",
        "\n",
        "  return losses,net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aha0LaxSIBPl"
      },
      "outputs": [],
      "source": [
        "# TRAIN model\n",
        "#############\n",
        "losses,net = function2trainTheModel()\n",
        "print(f'Final loss: {losses[-1]:.4f}')\n",
        "\n",
        "# visualize the losses\n",
        "plt.plot(losses,'.-')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Model loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6u2tLxJH_HF"
      },
      "outputs": [],
      "source": [
        "# create a decoder model, that just decodes the latent representation\n",
        "def fnDECODER():\n",
        "  class mydecoder(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "\n",
        "      self.lat = nn.Linear(16,600)          # latent layer\n",
        "\n",
        "      self.dec = nn.Linear(600,pix_per_side*pix_per_side)  # decoder layer\n",
        "\n",
        "    # forward pass\n",
        "    def forward(self,x):\n",
        "      x = F.relu( self.lat(x) )\n",
        "      y = torch.sigmoid( self.dec(x) )\n",
        "      return y\n",
        "\n",
        "  # create the model instance\n",
        "  decnet = mydecoder()\n",
        "\n",
        "  # copy the weights from the trained 'net' model to 'decnet'...\n",
        "  # for latent layer...\n",
        "  decnet.lat.weight.data = net.lat.weight.data\n",
        "  decnet.lat.bias.data = net.lat.bias.data\n",
        "  # and decoder layer...\n",
        "  decnet.dec.weight.data = net.dec.weight.data\n",
        "  decnet.dec.bias.data = net.dec.bias.data\n",
        "\n",
        "  return decnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGWwssyhHlUE"
      },
      "outputs": [],
      "source": [
        "decnet = fnDECODER()  # call the function and create the model\n",
        "\n",
        "\n",
        "remade1 = decnet(torch.rand(16))  # pass random noise to the decoder\n",
        "remade2 = decnet(torch.rand(16))\n",
        "remade3 = decnet(torch.rand(16))\n",
        "remade4 = decnet(torch.rand(16))\n",
        "remade5 = decnet(torch.rand(16))\n",
        "remade6 = decnet(torch.rand(16))\n",
        "\n",
        "# show images\n",
        "fig, axs = plt.subplots(1, 6, figsize=(12, 4)) # 1 row, 6 columns\n",
        "axs[0].imshow(remade1.view(pix_per_side, pix_per_side).detach())\n",
        "axs[1].imshow(remade2.view(pix_per_side, pix_per_side).detach())\n",
        "axs[2].imshow(remade3.view(pix_per_side, pix_per_side).detach())\n",
        "axs[3].imshow(remade4.view(pix_per_side, pix_per_side).detach())\n",
        "axs[4].imshow(remade5.view(pix_per_side, pix_per_side).detach())\n",
        "axs[5].imshow(remade6.view(pix_per_side, pix_per_side).detach())\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print('checkpoint 4')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
